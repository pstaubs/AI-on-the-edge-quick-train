{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. Additionally a category \"NaN\" is introduced, to mark images that are not amibiguous.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "\n",
    "TFliteNamingAndVersion = \"dig-overfitted\"   # Used for tflite Filename\n",
    "Training_Percentage = 0.0    # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 500\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from -1, 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 20x32 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='raw_digits_resized'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*/*.jpg')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for aktfile in files:\n",
    "    dirs = aktfile.split(os.sep)\n",
    "    target = dirs[1]\n",
    "    if target == \"N\":\n",
    "        category = 10                # NaN does not work --> convert to 10\n",
    "    else:\n",
    "        category = int(target)\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    x_data.append(test_image)\n",
    "    y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 11)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 20, 3)\n",
    "* Number of output layers: 11\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32, 20, 3))\n",
    "inputs2 = tf.keras.layers.BatchNormalization()(inputs)\n",
    "inputs3 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=\"relu\")(inputs2)\n",
    "inputs4 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(inputs3)\n",
    "inputs5 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=\"relu\")(inputs4)\n",
    "inputs6 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(inputs5)\n",
    "inputs7 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=\"relu\")(inputs6)\n",
    "inputs8 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(inputs7)\n",
    "inputs9 = tf.keras.layers.Flatten()(inputs8)\n",
    "inputs10 = tf.keras.layers.Dense(128,activation=\"relu\")(inputs9)\n",
    "output = tf.keras.layers.Dense(11, activation='softmax')(inputs10)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(BatchNormalization(input_shape=(32,20,3)))\n",
    "#model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "#model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "#model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "#model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128,activation=\"relu\"))\n",
    "#model.add(Dense(11, activation = \"softmax\"))\n",
    "#model.summary()\n",
    "\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Batch_Size = 4\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.3\n",
    "Rotation_Angle = 10\n",
    "ZoomRange = 0.4\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* x-axis walks through each pixel, y-axis shows the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check each image for expected and deviation\n",
    "* setting the switch \"only_deviation = true\" will only print the images for which the classification and the CNN-result deviates\n",
    "\n",
    "The output contains the following information:\n",
    "\n",
    "| Filename      | Expected Category           | Predicted Category        |\n",
    "|------------- |:-----------------------------:|--------------|\n",
    "| ziffer_sortiert_resize_NaN/5\\Ziffer_4_0034.jpg | 4  | -1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "only_deviation = True\n",
    "show_wrong_image = True\n",
    "\n",
    "files = glob.glob(Input_dir + '/*/*.jpg')\n",
    "\n",
    "for aktfile in files:\n",
    "    base = os.path.basename(aktfile)\n",
    "    dirs = aktfile.split(os.sep)\n",
    "    target = dirs[1]\n",
    "    if target == \"N\":\n",
    "        expected_class = -1\n",
    "    else:\n",
    "        expected_class = int(target)\n",
    "    image_in = Image.open(aktfile)\n",
    "    img = np.reshape(np.array(image_in, dtype=\"float32\"),[1,32,20,3])\n",
    "    prediction = np.argmax(model.predict(img), axis=-1)[0]\n",
    "    if prediction == 10: \n",
    "        prediction = -1\n",
    "    res.append(np.array([expected_class, prediction, prediction - expected_class]))\n",
    "    if only_deviation == True:\n",
    "        if str(prediction) != str(expected_class):\n",
    "            print(aktfile + \" \" + str(expected_class) +  \" \" + str(prediction))\n",
    "            if show_wrong_image == True:\n",
    "                display(image_in)\n",
    "    else:\n",
    "        print(aktfile + \" \" + aktsubdir +  \" \" + str(prediction))\n",
    "        \n",
    "\n",
    "res = np.asarray(res)\n",
    "\n",
    "\n",
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Digital Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['real','model'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = TFliteNamingAndVersion\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = TFliteNamingAndVersion + \"q.tflite\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def representative_dataset():\n",
    "    for n in range(x_data[0].size):\n",
    "      data = np.expand_dims(x_data[5], axis=0)\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.representative_dataset = representative_dataset\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName, \"wb\").write(tflite_quant_model)\n",
    "print(FileName)\n",
    "Path(FileName).stat().st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the images shows, that this are border line images, which can be interpreted as a good digit or a faulty one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
